{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Convotutional Neural Network (CNN) for simpson Image Recognition</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Show Samples in the Unknown Folder</h3>\n",
    "<pre>\n",
    "images\n",
    "    0: homer_simpson\n",
    "    1: lisa_simpson\n",
    "    2: marge_simpson\n",
    "    u: (unknown)\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ homer_simpson → class 0: train= 50, unknown=3\n",
      "✔ marge_simpson → class 1: train= 50, unknown=3\n",
      "✅ 全部圖片重新命名與分類完成！\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# 原始 simpson 資料夾\n",
    "SRC_DIR = Path(\"simpson\")\n",
    "DEST_DIR = Path(\"images\")\n",
    "UNKNOWN_DIR = DEST_DIR / \"u\"\n",
    "\n",
    "# 設定參數\n",
    "total_images_per_class = 53\n",
    "unknown_images_per_class = 3\n",
    "train_images_per_class = total_images_per_class - unknown_images_per_class\n",
    "image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "\n",
    "# 建立資料夾\n",
    "DEST_DIR.mkdir(exist_ok=True)\n",
    "UNKNOWN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 開始處理每個類別資料夾\n",
    "for idx, class_folder in enumerate(sorted(SRC_DIR.iterdir())):\n",
    "    if not class_folder.is_dir():\n",
    "        continue\n",
    "\n",
    "    image_files = [\n",
    "        f for f in class_folder.iterdir() if f.suffix.lower() in image_extensions\n",
    "    ]\n",
    "\n",
    "    if len(image_files) < total_images_per_class:\n",
    "        print(f\"{class_folder.name} 圖片不足 {total_images_per_class} 張，跳過\")\n",
    "        continue\n",
    "\n",
    "    random.shuffle(image_files)\n",
    "    selected_images = image_files[:total_images_per_class]\n",
    "    unknown_images = selected_images[:unknown_images_per_class]\n",
    "    train_images = selected_images[unknown_images_per_class:]\n",
    "\n",
    "    # 建立類別資料夾（以數字命名）\n",
    "    class_dir = DEST_DIR / str(idx)\n",
    "    class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 複製訓練圖片並重新命名為：class_name_000.jpg、001.jpg...\n",
    "    for i, img in enumerate(train_images):\n",
    "        new_name = f\"{class_folder.name}_{i:03d}.jpg\"\n",
    "        shutil.copy(img, class_dir / new_name)\n",
    "\n",
    "    # 複製 unknown 圖片 → 命名為 00.jpg, 01.jpg, ..., 10.jpg, 11.jpg...\n",
    "    for u_idx, img in enumerate(unknown_images):\n",
    "        number = idx * 10 + u_idx\n",
    "        new_name = f\"{class_folder.name}_{number:02d}.jpg\"\n",
    "        shutil.copy(img, UNKNOWN_DIR / new_name)\n",
    "\n",
    "    print(\n",
    "        f\"✔ {class_folder.name} → class {idx}: train= {len(train_images)}, unknown={len(unknown_images)}\"\n",
    "    )\n",
    "\n",
    "print(\"全部圖片重新命名與分類完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/u\\homer_simpson_00.jpg\n",
      "images/u\\homer_simpson_01.jpg\n",
      "images/u\\homer_simpson_02.jpg\n",
      "images/u\\marge_simpson_10.jpg\n",
      "images/u\\marge_simpson_11.jpg\n",
      "images/u\\marge_simpson_12.jpg\n"
     ]
    }
   ],
   "source": [
    "# Show Samples in the Unknown Folder\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "def show_sample(img):\n",
    "    # cv2.imshow 使用的 RGB 數值是 (0.0,1.0)\n",
    "    img = img / 255.0\n",
    "    # resize 影像至 (256,256) 方便觀看\n",
    "    img256 = cv2.resize(img, (256, 256))\n",
    "    # 顯示影像\n",
    "    cv2.namedWindow('Sample')\n",
    "    cv2.imshow('Sample', img256)\n",
    "    # 按下 SPACEBAR 關閉\n",
    "    while (True):\n",
    "        c = cv2.waitKey(500)\n",
    "        if (c == ord(' ')): \n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    return\n",
    "\n",
    "ilst = glob.glob('images/u/*.*')\n",
    "\n",
    "for f in ilst:\n",
    "    print(f)\n",
    "    img = cv2.imread(f)\n",
    "    show_sample(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Load all training samples of homer_simpson (0) & marge_simpson (1)</h3>\n",
    "<p>image_size = <strong style=\"color:red\">64</strong></p>\n",
    "<pre>\n",
    "images: all images (64x64x3)\n",
    "labels: all labels (2)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples are ready. (n=100)\n"
     ]
    }
   ],
   "source": [
    "# Load all training samples of homer_simpson (0) & marge_simpson (1)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Normalized size of sample images\n",
    "image_size = 64\n",
    "# Class index (labels): 0 and 1; (0 for homer_simpson & 1 for marge_simpson)\n",
    "class_num = 2\n",
    "class_name = [ 0, 1 ]\n",
    "\n",
    "# 計算樣本數\n",
    "count = 0\n",
    "for c in class_name:\n",
    "    clst = glob.glob('images/%d/*.*' % c)\n",
    "    for f in clst:\n",
    "        count = count + 1\n",
    "sample_n = count\n",
    "\n",
    "images = np.zeros([sample_n,image_size,image_size,3])\n",
    "labels = np.zeros([sample_n,class_num])\n",
    "\n",
    "count = 0\n",
    "for c in class_name:\n",
    "    clst = glob.glob('images/%d/*.*' % c)\n",
    "    for f in clst:\n",
    "        # rint(f)\n",
    "        img = cv2.imread(f)\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        # show_sample(img)\n",
    "        images[count,:,:,:] = img[:,:,:]\n",
    "        labels[count,:] = np.zeros([class_num])\n",
    "        labels[count,c] = 1\n",
    "        count = count + 1\n",
    "\n",
    "# print(images)\n",
    "# print(labels)\n",
    "\n",
    "print('Samples are ready. (n=%d)' % (sample_n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Basic Parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Parameters\n",
    "\n",
    "# 載入 modules\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# pytorch reproducible\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 設定基本參數並載入 MNIST Dataset\n",
    "\n",
    "# 基本參數\n",
    "\n",
    "# 訓練回合數\n",
    "EPOCH = 1000\n",
    "# Learning Rate (LR)\n",
    "LR = 0.001\n",
    "# (RGB Channels)\n",
    "CHANNEL = 3\n",
    "# 影像尺寸 IMAGE_SIZE x IMAGE_SIZE\n",
    "IMAGE_SIZE = image_size\n",
    "# 總樣本數\n",
    "N = sample_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>CNN 定義</h3>\n",
    "<pre>\n",
    "<span style=\"color:red\">CNN for 64x64 color images (RGB) (Cat vs. Dogs)</span>\n",
    "<span style=\"color:red\">4 convolutional layers</span>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop_out): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# CNN 定義\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # input shape (3, 64, 64),  (IN_CHANNEL=3, IMAGE_SIZE=64, IMAGE_SIZE=64)\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            # output shape (16, 64, 64), (OUT_CHANNEL=16, IMAGE_SIZE=64, IMAGE_SIZE=64)\n",
    "            # activation\n",
    "            nn.ReLU(),\n",
    "            # size=2x2, output shape (16, 32, 32), (OUT_CHANNEL=16, IMAGE_SIZE/2=32, IMAGE_SIZE/2=32)\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            # input shape (16, 32, 32), (IN_CHANNEL=16, IMAGE_SIZE/2=32, IMAGE_SIZE/2=32)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            # output shape (32, 32, 32), (OUT_CHANNEL=32, IMAGE_SIZE/2=32, IMAGE_SIZE/2=32)\n",
    "            # activation\n",
    "            nn.ReLU(),\n",
    "            # size=2x2, output shape (32, 16, 16), (OUT_CHANNEL=32, IMAGE_SIZE/4=16, IMAGE_SIZE/4=16)\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        # Convolutional Layer 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            # input shape (32, 16, 16), (IN_CHANNEL=32, IMAGE_SIZE/4=16, IMAGE_SIZE/4=16)\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            # output shape (64, 16, 16), (OUT_CHANNEL=64, IMAGE_SIZE/4=16, IMAGE_SIZE/4=16)\n",
    "            # activation\n",
    "            nn.ReLU(),\n",
    "            # size=2x2, output shape (64, 8, 8), (OUT_CHANNEL=64, IMAGE_SIZE/8=8, IMAGE_SIZE/8=8)\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        # Convolutional Layer 4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            # input shape (32, 16, 16), (IN_CHANNEL=64, IMAGE_SIZE/8=8, IMAGE_SIZE/8=8)\n",
    "            nn.Conv2d(64, 128, 5, 1, 2),\n",
    "            # output shape (64, 16, 16), (OUT_CHANNEL=128, IMAGE_SIZE/8=8, IMAGE_SIZE/8=8)\n",
    "            # activation\n",
    "            nn.ReLU(),\n",
    "            # size=2x2, output shape (128, 4, 4), (OUT_CHANNEL=128, IMAGE_SIZE/16=4, IMAGE_SIZE/16=4)\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        # Dropout，丟掉一些 weights，防止 overfitting\n",
    "        self.drop_out = nn.Dropout()\n",
    "        # Fully connected layer 1, output 1024 classes, (IN=128*4*4=1024, OUT=256)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * int(IMAGE_SIZE/16) * int(IMAGE_SIZE/16), 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Fully connected layer 2, output 16 classes, (IN=256, OUT=16)\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Fully connected layer 3, output 2 classes, (IN=16, OUT=2)\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        net = self.conv1(x)\n",
    "        net = self.conv2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.conv4(net)\n",
    "        # CNN reshape, (batch_size, 128 * 4 * 4)\n",
    "        # net = net.view(net.size(0), -1)\n",
    "        net = net.contiguous().view(net.size(0), -1)\n",
    "        net= self.drop_out(net)\n",
    "        net= self.fc1(net)\n",
    "        net= self.fc2(net)\n",
    "        output = self.fc3(net)\n",
    "        return output\n",
    "\n",
    "# CNN 產生\n",
    "cnn = CNN()\n",
    "\n",
    "# net architecture\n",
    "print(cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>改變影像資料的維度排列方式，配合 CNN 所需的維度</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64, 64, 3)\n",
      "(100, 64, 64, 3)\n",
      "(100, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# 改變影像資料的維度排列方式，配合 CNN 所需的維度\n",
    "\n",
    "# 原始影像集：個數 x 影像高度 x 影像寬度 x 色頻數\n",
    "print(images.shape)\n",
    "\n",
    "# 新影像集\n",
    "images_for_cnn = images.copy()\n",
    "\n",
    "print(images_for_cnn.shape)\n",
    "\n",
    "# 維度轉換\n",
    "# 維度二與維度三互換\n",
    "images_for_cnn = np.swapaxes(images_for_cnn, 2, 3)\n",
    "# 維度一與維度二互換\n",
    "images_for_cnn = np.swapaxes(images_for_cnn, 1, 2)\n",
    "\n",
    "# 新影像集：個數 x 色頻數 x 影像高度 x 影像寬度\n",
    "print(images_for_cnn.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>影像集 ndarray 格式轉換為 Tensor 格式</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 影像集 ndarray 格式轉換為 Tensor 格式\n",
    "\n",
    "x = torch.from_numpy(images_for_cnn).float()\n",
    "y = torch.from_numpy(labels).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 64, 64])\n",
      "torch.Size([100, 2])\n",
      "tensor([[[ 36.,  35.,  37.,  ...,  16.,  23.,  24.],\n",
      "         [ 22.,  15.,  43.,  ...,   0.,  25.,  14.],\n",
      "         [ 36.,  38.,  27.,  ...,  29.,  29.,  25.],\n",
      "         ...,\n",
      "         [ 26.,  25.,  22.,  ...,  16.,  21.,  22.],\n",
      "         [ 24.,  27.,  10.,  ...,  22.,  30.,  26.],\n",
      "         [ 19.,  22.,  10.,  ...,  17.,  25.,  21.]],\n",
      "\n",
      "        [[ 42.,  42.,  44.,  ...,  58.,  59.,  60.],\n",
      "         [ 28.,  22.,  50.,  ...,  26.,  58.,  49.],\n",
      "         [ 40.,  44.,  43.,  ...,  48.,  48.,  44.],\n",
      "         ...,\n",
      "         [ 28.,  28.,  34.,  ...,  35.,  34.,  34.],\n",
      "         [ 27.,  32.,  29.,  ...,  41.,  44.,  40.],\n",
      "         [ 22.,  27.,  29.,  ...,  36.,  39.,  35.]],\n",
      "\n",
      "        [[117., 118., 129.,  ..., 145., 138., 138.],\n",
      "         [103.,  98., 135.,  ..., 115., 138., 128.],\n",
      "         [121., 125., 126.,  ..., 121., 121., 117.],\n",
      "         ...,\n",
      "         [ 99.,  99., 106.,  ..., 103., 104., 104.],\n",
      "         [102., 107., 102.,  ..., 109.,  99.,  93.],\n",
      "         [ 97., 102., 102.,  ..., 104.,  94.,  88.]]])\n",
      "tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Move to GPU if CUDA Available</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Move to GPU if CUDA Available\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "cnn.to(device)\n",
    "\n",
    "x, y = x.to(device), y.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>CNN Model Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0,     2.401342315674\n",
      "   10,     0.531620712280\n",
      "   20,     0.511378936768\n",
      "   30,     0.506932106018\n",
      "   40,     0.503997497559\n",
      "   50,     0.506200523376\n",
      "   60,     0.501744346619\n",
      "   70,     0.490384445190\n",
      "   80,     0.472886047363\n",
      "   90,     0.403548774719\n",
      "  100,     0.232901611328\n",
      "  110,     0.106919670105\n",
      "  120,     0.053686437607\n",
      "  130,     0.025192723274\n",
      "  140,     0.021510856152\n",
      "  150,     0.013190878630\n",
      "  160,     0.013712807894\n",
      "  170,     0.013665069342\n",
      "  180,     0.012194274664\n",
      "  190,     0.008483516574\n",
      "  200,     0.009896321297\n",
      "  210,     0.008644857407\n",
      "  220,     0.006964403391\n",
      "  230,     0.008948934078\n",
      "  240,     0.006407318711\n",
      "  250,     0.007596824169\n",
      "  260,     0.008185850382\n",
      "  270,     0.005581636429\n",
      "  280,     0.006908971667\n",
      "  290,     0.006295160055\n",
      "  300,     0.004879609048\n",
      "  310,     0.005585486889\n",
      "  320,     0.007198413610\n",
      "  330,     0.004789264500\n",
      "  340,     0.004968159497\n",
      "  350,     0.004810029864\n",
      "  360,     0.009732160568\n",
      "  370,     0.006639716625\n",
      "  380,     0.004725511968\n",
      "  390,     0.004875949919\n",
      "  400,     0.004654790163\n",
      "  410,     0.003966246843\n",
      "  420,     0.004611232281\n",
      "  430,     0.004133610129\n",
      "  440,     0.002646268606\n",
      "  450,     0.003914698660\n",
      "  460,     0.003616926372\n",
      "  470,     0.003790757656\n",
      "  480,     0.002889908850\n",
      "  490,     0.003684988618\n",
      "  500,     0.003372129202\n",
      "  510,     0.003193339705\n",
      "  520,     0.003918858767\n",
      "  530,     0.003671829700\n",
      "  540,     0.003737784922\n",
      "  550,     0.003647884130\n",
      "  560,     0.002970424294\n",
      "  570,     0.003811397254\n",
      "  580,     0.003812621236\n",
      "  590,     0.003319634497\n",
      "  600,     0.002794243693\n",
      "  610,     0.002875784636\n",
      "  620,     0.002922745049\n",
      "  630,     0.004844684005\n",
      "  640,     0.002787522674\n",
      "  650,     0.003905033469\n",
      "  660,     0.003575471044\n",
      "  670,     0.004559375048\n",
      "  680,     0.002721214294\n",
      "  690,     0.001862002015\n",
      "  700,     0.002206488699\n",
      "  710,     0.002281170189\n",
      "  720,     0.003569058776\n",
      "  730,     0.002665971518\n",
      "  740,     0.003047389984\n",
      "  750,     0.002894201577\n",
      "  760,     0.002455387563\n",
      "  770,     0.003528410792\n",
      "  780,     0.002335872203\n",
      "  790,     0.002771948874\n",
      "  800,     0.002339898348\n",
      "  810,     0.002545464039\n",
      "  820,     0.001763210148\n",
      "  830,     0.002192812711\n",
      "  840,     0.002102964371\n",
      "  850,     0.002200121582\n",
      "  860,     0.002550507188\n",
      "  870,     0.002936627269\n",
      "  880,     0.002328689843\n",
      "  890,     0.003153334558\n",
      "  900,     0.002089206874\n",
      "  910,     0.002324587107\n",
      "  920,     0.001899757236\n",
      "  930,     0.002282868773\n",
      "  940,     0.001830652356\n",
      "  950,     0.002306166738\n",
      "  960,     0.003366405964\n",
      "  970,     0.002403356880\n",
      "  980,     0.002630210519\n",
      "  990,     0.002613990009\n",
      " 1000,     0.002550515532\n"
     ]
    }
   ],
   "source": [
    "# CNN model training\n",
    "\n",
    "# cnn training\n",
    "def cnn_training(cnn, test_x, test_y):\n",
    "    # loss function changed to be MSE (from Cross Entropy)\n",
    "    loss_func = torch.nn.MSELoss(reduction='sum')\n",
    "    # optimize all cnn parameters\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "    # Training iteratively\n",
    "    for epoch in range(EPOCH+1):\n",
    "        # shuffle\n",
    "        indices = torch.randperm(x.size()[0])\n",
    "        new_x, new_y = x[indices], y[indices]\n",
    "        # cnn output\n",
    "        output = cnn(new_x)\n",
    "        # cross entropy loss\n",
    "        loss = loss_func(output, new_y)\n",
    "        # display err\n",
    "        if (epoch % 10 == 0):\n",
    "            err = loss.item() / sample_n\n",
    "            print('%5d, %18.12f' % (epoch, err))\n",
    "        # clear gradients for this training step\n",
    "        optimizer.zero_grad()\n",
    "        # backpropagation, compute gradients\n",
    "        loss.backward()\n",
    "        # apply gradients\n",
    "        optimizer.step()\n",
    "    return cnn\n",
    "\n",
    "cnn = cnn_training(cnn, x, y)\n",
    "\n",
    "# Save torch model\n",
    "torch.save(cnn.state_dict(), 'cnn_simpson.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Load CNN Model of CD samples</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load previous cnn model completely!\n"
     ]
    }
   ],
   "source": [
    "# Load CNN Model of CD samples\n",
    "\n",
    "def load_cnn_model():\n",
    "    # Load torch model\n",
    "    cnn.load_state_dict(torch.load('cnn_simpson.model', map_location='cpu'))\n",
    "    cnn.eval()\n",
    "    print('Load previous cnn model completely!')\n",
    "    return\n",
    "    \n",
    "load_cnn_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Test Unknown Samples</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖片: images/u\\homer_simpson_00.jpg → 預測類別: homer_simpson\n",
      "圖片: images/u\\homer_simpson_01.jpg → 預測類別: homer_simpson\n",
      "圖片: images/u\\homer_simpson_02.jpg → 預測類別: homer_simpson\n",
      "圖片: images/u\\marge_simpson_10.jpg → 預測類別: marge_simpson\n",
      "圖片: images/u\\marge_simpson_11.jpg → 預測類別: marge_simpson\n",
      "圖片: images/u\\marge_simpson_12.jpg → 預測類別: marge_simpson\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 類別索引對應\n",
    "label_dict = {\n",
    "    0: 'homer_simpson',\n",
    "    1: 'marge_simpson'\n",
    "}\n",
    "\n",
    "def cnn_testing():\n",
    "    ilst = glob.glob('images/u/*.*')\n",
    "    res = []\n",
    "\n",
    "    for f in ilst:\n",
    "        img = cv2.imread(f)\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "\n",
    "        # 調整 shape 為 (3, H, W)\n",
    "        img = np.swapaxes(img, 1, 2)\n",
    "        img = np.swapaxes(img, 0, 1)\n",
    "\n",
    "        # 準備 tensor 並轉成 float\n",
    "        x = torch.zeros(1, 3, image_size, image_size)\n",
    "        x[0] = torch.from_numpy(img).float()\n",
    "        x = x.to(device)\n",
    "\n",
    "        # 預測\n",
    "        output = cnn(x)\n",
    "        pred_class = torch.argmax(output, dim=1).item()  # 取最大機率的類別 index\n",
    "\n",
    "        # 對應成類別名稱\n",
    "        pred_label = label_dict[pred_class]\n",
    "        res.append([f, pred_label])\n",
    "    \n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    res = cnn_testing()\n",
    "    for r in res:\n",
    "        print(f\"圖片: {r[0]} → 預測類別: {r[1]}\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
